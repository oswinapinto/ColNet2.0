{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the precision, recall and F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "current_path = os.getcwd()\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    '--threshold',\n",
    "    type=float,\n",
    "    default=0.16,\n",
    "    help='Threshold to determine a column class')\n",
    "parser.add_argument(\n",
    "    '--predictions',\n",
    "    type=str,\n",
    "\n",
    "    # default=os.path.join(current_path, 'output/predictions/p_lookup.json'),\n",
    "    # default=os.path.join(current_path, 'output/predictions/p_cnn_1_2_1.00.json'),\n",
    "\n",
    "    default=os.path.join(\n",
    "        current_path, 'output/predictions/p_cnn_1_2_1.00_lookup.json'),\n",
    "    help='Prediction file')\n",
    "parser.add_argument(\n",
    "    '--ground_truths',\n",
    "    type=str,\n",
    "    default=os.path.join(current_path, '../SemTab_DataSets/Round1DataSets/Valid/gt/cea_gt.csv'),\n",
    "    help='Ground truths')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as json_file:\n",
    "        return json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.458, Precision: 0.458, Recall: 0.458\n"
     ]
    }
   ],
   "source": [
    "wd_prefix = 'http://www.wikidata.org/entity/'\n",
    "\n",
    "# read columns and the ground truth\n",
    "col_gt_classes = dict()\n",
    "gt = pd.read_csv(os.path.join(current_path, FLAGS.ground_truths), delimiter=',', names=['tab_id', 'row_id', 'col_id', 'entity'],\n",
    "                 dtype={'tab_id': str, 'row_id': str, 'col_id': str, 'entity': str}, keep_default_na=False, nrows=100)\n",
    "for index, row in gt.iterrows():\n",
    "    cells = col_gt_classes.keys()\n",
    "    if row['tab_id'] in cells:\n",
    "        gt_value = col_gt_classes[cell]\n",
    "        gt_value.append(row['entity'].split(wd_prefix)[1])\n",
    "    else:\n",
    "        cell = '%s' % (row['tab_id'])\n",
    "        gt_value = [row['entity'].split(wd_prefix)[1]]\n",
    "    col_gt_classes[cell] = gt_value\n",
    "\n",
    "# read the column, predicted column and scores\n",
    "col_pclasses = dict()\n",
    "p_classes = load_json(FLAGS.predictions)\n",
    "for key, value in p_classes.items():\n",
    "    col_cls = key.split(',')\n",
    "    col, cls = col_cls\n",
    "    score = float(value)\n",
    "    if score >= FLAGS.threshold:\n",
    "        if col in col_pclasses:\n",
    "            col_pclasses[col].append(cls)\n",
    "        else:\n",
    "            col_pclasses[col] = [cls]\n",
    "\n",
    "# calculating metrics\n",
    "correct_cells, annotated_cells = set(), set()\n",
    "for cell in col_gt_classes:\n",
    "    try:\n",
    "        if cell not in annotated_cells:\n",
    "            annotated_cells.add(cell)\n",
    "        ann_cells = set(col_pclasses[cell] )\n",
    "        gt_cells = set(col_gt_classes[cell])\n",
    "        if len(ann_cells.intersection(gt_cells)) > 0 :\n",
    "            correct_cells.add(cell)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "precision = len(correct_cells) / \\\n",
    "    len(annotated_cells) if len(annotated_cells) > 0 else 0.0\n",
    "recall = len(correct_cells) / len(col_gt_classes.keys())\n",
    "f1 = (2 * precision * recall) / (precision +\n",
    "                                 recall) if (precision + recall) > 0 else 0.0\n",
    "main_score = f1\n",
    "secondary_score = precision\n",
    "print('F1: %.3f, Precision: %.3f, Recall: %.3f' %\n",
    "      (f1, precision, recall))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('colnet-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31dfa0067d95d91f2293773f41a1bcba4d2bbc525ad33be42c4f090f17bf1713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
